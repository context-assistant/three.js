Acting as an expert project manager, please use the information below to write a comprehensive multi-phase plan to build this system.  Save this plain in ./cursor/plan.prompt.md.  In this plan you will specify that we will build the project, it's tooling, documentation, and instructions for ai agents seeing the project for the first time. PLEASE ASK QUALIFYING QUESTIONS BEFORE WRITING THIS PLAN.

# RULES

- We do NOT want to edit the three.js project directly.  Ideally we will be able to pull upstream changes without major refactoring work.
- We will contain all codebase changes to the "context-assistant" and ".cursor" folders. WE WILL NOT ALLOW AGENTS TO EDIT CODE OUTSIDE OF THESE PATHS.
- The "context-assistant" folder will be a new project that wraps this three.js project using a same origin iFrame, decoupling us from the namespace but still allowing us access to manipulate the various site pages, like the the three.js editor, three.js playground, three.js manual, and three.js API documents.  We will maintain separate iframes for the three.js editor, three.js playground, and documents pages.  The api docs and api manual will share the same iframe. 
- These iframes can be added and removed from our root window as needed.
- We will inject our integration scripts after loading these iframes.
- Our integration scripts will enhance the iframe with the features we are adding, for example, in the three.js editor project we might inject an integration script that allows us access to editor object and read details about the editor scene.
- We want this integration system code to be simple, modular, and human readable
- our "context-assistant" app will be written in typescript and styled with tailwind, with it's own package.json and compile step, separate from the three.js project.
- the context-assistant app will have a navbar at the top of the page and a main content section below that, filling the rest of the available height of the viewport, with overflow-y auto.  The landing page for this app will describe what this project does and have links to other sections of the project (Editor, Playground, Manual, Documentation).  These links will also be nav items in the top nav.  Clicking on a nav item will open the respective iframe, replacing the main section (filling the viewport below our top nav).
- The top right of this nav bar will contain our AI assistant button.  Clicking on this button will open an overlay, right-side panel with an ai chat interface.  This chat interface will fill the height of the viewport, has resizable width, and will lay on top of the main section.
- our AI assistant chat interface will be a simple chat bubble container filling the top, left, and right available space. The chat bubble container will flex it's height depending on how much text the user has typed into the prompt input textarea that will be at the bottom of this side-panel. The prompt input textarea will start as 4 rows tall, but will expand up to 11 rows tall while the user is typing.  The bottom row of the textarea will padding so that the text will not overflow into the last row.  Instead we will have a ui overlay on the bottom row of the text area that contains an "agent" selectbox, and button icons for 'clear chat', 'settings', '@' (@mention objects in the scene), and a 'send' button that turns into an abort button while waiting on a prompt response.
- we will have a settings view that is accessible from our top nav.  This will open our settings view where we will configure the LLM settings 'ollama endpoint', and 'persist chat history'. here we will also have our "agent builder", that is basically a way for us to save agent config.  We will use a locally running ollama server to list, manage and call AI models.  Our agent config will let us save settings, context_window, max_size, temperature, top_k, top_n, mirostat, mirostat tau, mirostat eta, and agent config for agent language and personality traits, shown as a list of personality traits that are either switched on or off (funny, sarcastic, optimistic, etc..).